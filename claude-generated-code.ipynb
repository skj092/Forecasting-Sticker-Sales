{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5535d11",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-01T06:23:51.751736Z",
     "iopub.status.busy": "2025-01-01T06:23:51.751240Z",
     "iopub.status.idle": "2025-01-01T06:25:40.942495Z",
     "shell.execute_reply": "2025-01-01T06:25:40.941072Z"
    },
    "papermill": {
     "duration": 109.197024,
     "end_time": "2025-01-01T06:25:40.944292",
     "exception": false,
     "start_time": "2025-01-01T06:23:51.747268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train_data shape: (230130, 6)\n",
      "Initial test_data shape:  (98550, 5)\n",
      "=== Training XGB ===\n",
      "XGB - Mean CV MAPE: 0.0120\n",
      "\n",
      "=== Training LGBM ===\n",
      "LGBM - Mean CV MAPE: 0.0125\n",
      "\n",
      "=== Training CatBoost ===\n",
      "CatBoost - Mean CV MAPE: 0.0136\n",
      "\n",
      "Sample Submission Preview:\n",
      "       id    num_sold\n",
      "0  230130  125.866334\n",
      "1  230131  730.129967\n",
      "2  230132  650.911569\n",
      "3  230133  331.994435\n",
      "4  230134  399.649217\n",
      "\n",
      "Submission file 'submission_ensemble.csv' created!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Models\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# ----------------- CONFIG -------------------\n",
    "# You can tune these or load from a hyperparameter search\n",
    "xgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 8,\n",
    "    'min_child_weight': 8,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'gamma': 0.0,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 1.0,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': -1,\n",
    "    'num_leaves': 64,\n",
    "    'min_child_samples': 20,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 0.0,\n",
    "    'reg_lambda': 1.0,\n",
    "    'verbosity': -1,\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "cat_params = {\n",
    "    'iterations': 500,\n",
    "    'learning_rate': 0.05,\n",
    "    'depth': 8,\n",
    "    'loss_function': 'MAPE',\n",
    "    'random_state': 42,\n",
    "    'silent': True\n",
    "}\n",
    "\n",
    "N_SPLITS = 5  # KFold splits\n",
    "\n",
    "# ----------------- READ DATA -------------------\n",
    "# Kaggle environment:\n",
    "#   /kaggle/input/playground-series-s5e1/train.csv\n",
    "#   /kaggle/input/playground-series-s5e1/test.csv\n",
    "#   /kaggle/input/playground-series-s5e1/sample_submission.csv\n",
    "path = Path(\"/kaggle/input/playground-series-s5e1\")\n",
    "train_data = pd.read_csv(path/'train.csv')\n",
    "test_data  = pd.read_csv(path/'test.csv')\n",
    "sample_sub = pd.read_csv(path/'sample_submission.csv')\n",
    "\n",
    "print(\"Initial train_data shape:\", train_data.shape)\n",
    "print(\"Initial test_data shape: \", test_data.shape)\n",
    "\n",
    "# ----------------- CLEAN & PREPARE TRAIN -------------------\n",
    "# 1) Drop duplicates\n",
    "train_data.drop_duplicates(inplace=True)\n",
    "\n",
    "# 2) Drop missing target rows\n",
    "train_data.dropna(subset=['num_sold'], inplace=True)\n",
    "\n",
    "# 3) Convert 'date' to datetime if needed\n",
    "train_data['date'] = pd.to_datetime(train_data['date'], errors='coerce')\n",
    "test_data['date']  = pd.to_datetime(test_data['date'],  errors='coerce')\n",
    "\n",
    "# 4) Extract date features (you can add day-of-week, etc. if you want)\n",
    "train_data['Year']  = train_data['date'].dt.year\n",
    "train_data['Month'] = train_data['date'].dt.month\n",
    "train_data['Day']   = train_data['date'].dt.day\n",
    "\n",
    "test_data['Year']  = test_data['date'].dt.year\n",
    "test_data['Month'] = test_data['date'].dt.month\n",
    "test_data['Day']   = test_data['date'].dt.day\n",
    "\n",
    "# 5) Drop the 'date' column if you no longer need it directly\n",
    "train_data.drop('date', axis=1, inplace=True)\n",
    "test_data.drop('date',  axis=1, inplace=True)\n",
    "\n",
    "# 6) Log-transform the target\n",
    "train_data['num_sold'] = np.log1p(train_data['num_sold'])\n",
    "\n",
    "# 7) Drop 'id' from training, we'll use it from test\n",
    "train_data.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Identify numerical and categorical columns\n",
    "num_cols = train_data.select_dtypes(include=np.number).drop(columns=['num_sold']).columns.tolist()\n",
    "cat_cols = train_data.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# The test set also has 'id', we'll keep it for submission\n",
    "# but we won't use it as a feature\n",
    "test_ids = test_data['id'].copy()  # save for submission\n",
    "test_data.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# ----------------- ENCODE CATEGORICAL -------------------\n",
    "label_encoders = {}\n",
    "for col in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    train_data[col] = le.fit_transform(train_data[col])\n",
    "    label_encoders[col] = le\n",
    "\n",
    "    # Transform test data with the same encoder\n",
    "    if col in test_data.columns:\n",
    "        test_data[col] = le.transform(test_data[col])\n",
    "\n",
    "# ----------------- SEPARATE FEATURES/TARGET -------------------\n",
    "X = train_data.drop(['num_sold'], axis=1)\n",
    "y = train_data['num_sold']\n",
    "X_test_final = test_data.copy()  # for final predictions\n",
    "\n",
    "# ----------------- DEFINE MAPE -------------------\n",
    "def mape(y_true, y_pred):\n",
    "    return mean_absolute_percentage_error(y_true, y_pred)\n",
    "\n",
    "# ----------------- CROSS-VALIDATION FUNCTIONS -------------------\n",
    "def cross_val_xgb(X, y, X_test, params, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "    test_preds_list = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        score = mape(y_valid, y_pred_valid)\n",
    "        mape_scores.append(score)\n",
    "\n",
    "        # Predict on the test set\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_preds_list.append(y_test_pred)\n",
    "\n",
    "    # Average test predictions across folds\n",
    "    test_preds_mean = np.mean(test_preds_list, axis=0)\n",
    "    return np.mean(mape_scores), test_preds_mean\n",
    "\n",
    "def cross_val_lgbm(X, y, X_test, params, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "    test_preds_list = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        score = mape(y_valid, y_pred_valid)\n",
    "        mape_scores.append(score)\n",
    "\n",
    "        # Predict on test\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_preds_list.append(y_test_pred)\n",
    "\n",
    "    test_preds_mean = np.mean(test_preds_list, axis=0)\n",
    "    return np.mean(mape_scores), test_preds_mean\n",
    "\n",
    "def cross_val_catboost(X, y, X_test, params, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    mape_scores = []\n",
    "    test_preds_list = []\n",
    "\n",
    "    for train_idx, valid_idx in kf.split(X):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "        y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n",
    "\n",
    "        model = CatBoostRegressor(**params)\n",
    "        model.fit(X_train, y_train, eval_set=(X_valid, y_valid), verbose=False)\n",
    "\n",
    "        y_pred_valid = model.predict(X_valid)\n",
    "        score = mape(y_valid, y_pred_valid)\n",
    "        mape_scores.append(score)\n",
    "\n",
    "        # Predict on test\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        test_preds_list.append(y_test_pred)\n",
    "\n",
    "    test_preds_mean = np.mean(test_preds_list, axis=0)\n",
    "    return np.mean(mape_scores), test_preds_mean\n",
    "\n",
    "# ----------------- TRAIN & PREDICT WITH EACH MODEL -------------------\n",
    "print(\"=== Training XGB ===\")\n",
    "xgb_cv_score, xgb_test_preds = cross_val_xgb(X, y, X_test_final, xgb_params, n_splits=N_SPLITS)\n",
    "print(f\"XGB - Mean CV MAPE: {xgb_cv_score:.4f}\")\n",
    "\n",
    "print(\"\\n=== Training LGBM ===\")\n",
    "lgb_cv_score, lgb_test_preds = cross_val_lgbm(X, y, X_test_final, lgb_params, n_splits=N_SPLITS)\n",
    "print(f\"LGBM - Mean CV MAPE: {lgb_cv_score:.4f}\")\n",
    "\n",
    "print(\"\\n=== Training CatBoost ===\")\n",
    "cat_cv_score, cat_test_preds = cross_val_catboost(X, y, X_test_final, cat_params, n_splits=N_SPLITS)\n",
    "print(f\"CatBoost - Mean CV MAPE: {cat_cv_score:.4f}\")\n",
    "\n",
    "# ----------------- ENSEMBLE / BLEND -------------------\n",
    "# A simple approach is an unweighted average\n",
    "ensemble_test_preds = (xgb_test_preds + lgb_test_preds + cat_test_preds) / 3.0\n",
    "\n",
    "# You could also do a weighted average if one model is much stronger:\n",
    "# ensemble_test_preds = (0.4 * lgb_test_preds) + (0.3 * xgb_test_preds) + (0.3 * cat_test_preds)\n",
    "\n",
    "# ----------------- CREATE SUBMISSION -------------------\n",
    "# Recall we log-transformed the target, so exponentiate predictions\n",
    "final_num_sold = np.expm1(ensemble_test_preds)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'num_sold': final_num_sold\n",
    "})\n",
    "\n",
    "print(\"\\nSample Submission Preview:\")\n",
    "print(submission.head())\n",
    "\n",
    "submission.to_csv(\"submission_ensemble.csv\", index=False)\n",
    "print(\"\\nSubmission file 'submission_ensemble.csv' created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9c7cd4",
   "metadata": {
    "papermill": {
     "duration": 0.001815,
     "end_time": "2025-01-01T06:25:40.948503",
     "exception": false,
     "start_time": "2025-01-01T06:25:40.946688",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 10652996,
     "sourceId": 85723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 112.377352,
   "end_time": "2025-01-01T06:25:41.872274",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-01T06:23:49.494922",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
